{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "path = ''\n",
    "file_name = ''\n",
    "\n",
    "os.chdir(path)\n",
    "interventions = []\n",
    "with open(file_name, 'r') as f:\n",
    "    for line in f:\n",
    "        interventions.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract all the text snippet that contains the parenthesis.\n",
    "- assume the phrase in the parenthesis are the abbreviations...\n",
    "- separate if multiple abbreviations appeared in one text snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "acronyms = []\n",
    "import re\n",
    "for item in interventions:\n",
    "    if re.search(r'\\(.*?\\)', item) is not None:\n",
    "        acronyms.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hydroxychloroquine ( HCQ )', 'and lopinavir / ritonavir ( LPV / r )']\n"
     ]
    }
   ],
   "source": [
    "# separate if multiple abbreviations appeared in one text snippet\n",
    "def separate(item):\n",
    "    indexes = [pos for pos, char in enumerate(item) if char == ')']\n",
    "    phrases = []\n",
    "    indexes.insert(0, -1)\n",
    "    for i in range(1, len(indexes)):\n",
    "        if indexes[i] == indexes[i - 1]:\n",
    "            continue\n",
    "        phrases.append(item[indexes[i - 1] + 1 : indexes[i] + 1].strip())\n",
    "    print(phrases)\n",
    "    return phrases\n",
    "    \n",
    "for item in acronyms:\n",
    "    if len(re.findall(r'\\(.*?\\)', item)) > 1:\n",
    "        acronyms.remove(item)\n",
    "        acronyms_sep = acronyms + separate(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Remove unqualified phrases\n",
    "- if the phrase in the parenthesis contains punctuations (e.g. comma, semi-colon, peroid), then ignore it.\n",
    "- if the phrase does not contain upper-case characters, ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in acronyms_sep:\n",
    "    inner = re.search(r'\\(.*?\\)', item).group(0)\n",
    "    if re.search('[\\.,ï¼š]', inner) is not None:\n",
    "        acronyms_sep.remove(item)\n",
    "    if re.search('[A-Z]', inner) is None:\n",
    "        acronyms_sep.remove(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Functions used to match the abbreviations to full names\n",
    "- outer_inner(item): extract the text left to the parentheses, and the text in the parentheses\n",
    "- get_strings(outer, inner): a list of string lists recognized as potential full name for the inner abbreviation, the potential string list is recognized when the initial of the first word matches the first character of the abbreviations.\n",
    "- match_1(word_list, inner): for the abbreviation without lower-case character, if the potential full name contains less than 2 words, then the initals should match the abbreviation, if more than 2 words, then there should exist at least 2 consecutive initials that could be found in the abbreviation. (because some initials may be ignored in the abbreviations)\n",
    "- match_2(word_list, inner): for the abbreviation with lower-case characters, the lowercase characters together with the first left upper case character should match a word in the potential full name (initial n character match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "# detect the full name\n",
    "# apply the rules defined from the paper\n",
    "\n",
    "def outer_inner(item):\n",
    "    outer = item[:item.find('(')]\n",
    "    inner = re.search(r'\\((.*?)\\)', item).group(1).strip()\n",
    "    return outer, inner\n",
    "\n",
    "def get_strings(outer, inner):\n",
    "    target = inner[0]\n",
    "    word_list = word_tokenize(outer)\n",
    "    result_list = []\n",
    "    for index, word in enumerate(word_list):\n",
    "        if re.match(rf'{target}.*', word, re.I):\n",
    "            result_list.append((word_list[index:]))\n",
    "    return result_list\n",
    "\n",
    "def match_1(word_list, inner):\n",
    "    if len(word_list) <= 2:\n",
    "        for index, word in enumerate(word_list):\n",
    "            if word[0].lower() != inner[index].lower():\n",
    "                return False\n",
    "        return True\n",
    "    else:\n",
    "        for i in range(1,len(word_list) - 1):\n",
    "            temp = word_list[i -1][0] + word_list[i][0]\n",
    "            if re.search(temp, inner, re.I):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "def match_2(word_list, inner):\n",
    "    target = re.search(r'[A-Z][a-z]+', inner).group(0)\n",
    "    for word in word_list:\n",
    "        if re.search(target, word, re.I):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Map the abbreviations to full names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_mapper = {}\n",
    "# tranverse all the text snippet\n",
    "for item in acronyms_sep:\n",
    "#     extract all the potential full names for the abbreviation\n",
    "    outer, inner = outer_inner(item)\n",
    "    potential = get_strings(outer, inner)\n",
    "    \n",
    "#     if no potential full name, continue\n",
    "    if len(potential) == 0:\n",
    "        continue\n",
    "    \n",
    "#     if abbreviation does not contain lower-case character\n",
    "    if re.search(r'[A-Z][a-z]+', inner) is None:\n",
    "        for word_list in potential:\n",
    "#             if contains only one word, then add to dict\n",
    "            if len(word_list) == 1:\n",
    "                ab_mapper[inner] = word_list[0]\n",
    "                break\n",
    "            if match_1(word_list, inner):\n",
    "                ab_mapper[inner] = ' '.join(word_list)\n",
    "                break\n",
    "#    if abbreviation contains lower-case character\n",
    "    else:\n",
    "        for word_list in potential:\n",
    "#             if contains only one word, then add to the dict\n",
    "            if len(word_list) == 1:\n",
    "                ab_mapper[inner] = word_list[0]\n",
    "                break\n",
    "            if match_2(word_list, inner):\n",
    "                ab_mapper[inner] = ' '.join(word_list)\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Todos:\n",
    "- what if abbreviations contains multiple words? (revisively identify each word...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
